{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06b313a8",
   "metadata": {},
   "source": [
    "## Libraries and settings\n",
    "\n",
    "In diesem Abschnitt werden alle benötigten Bibliotheken importiert und die wichtigsten Einstellungen gesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe132fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/data_analytics_project/.venv/bin/python\n",
      "/workspaces/data_analytics_project/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import warnings\n",
    "import sys\n",
    "print(sys.executable)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a6424",
   "metadata": {},
   "source": [
    "# Weather & Bicycle Usage – Data Collection\n",
    "\n",
    "In diesem Notebook werden Wetter- und Veloverkehrsdaten für Zürich gesammelt, inspiziert und für die weitere Analyse vorbereitet. Die Daten stammen aus offenen Quellen und werden im Rahmen des Data Analytics Projekts nach ZHAW-Style verarbeitet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e0b97d",
   "metadata": {},
   "source": [
    "# Zurich Weather & Bicycle Usage\n",
    "\n",
    "Dieses Projekt analysiert den Zusammenhang zwischen Wetterdaten und Veloverkehr in Zürich anhand aktueller, offener Datenquellen. Es werden alle Schritte eines Data-Analytics-Projekts abgedeckt: Datensammlung, -aufbereitung, -speicherung, explorative Analyse, Modellierung und geografische Visualisierung."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0608d72c",
   "metadata": {},
   "source": [
    "# Weather & Bicycle Usage – Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d6c2dc",
   "metadata": {},
   "source": [
    "## Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "934b358c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/data_analytics_project/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def2bcbf",
   "metadata": {},
   "source": [
    "## Fetching weather data from Open-Meteo API\n",
    "\n",
    "We retrieve historical weather data for Zurich (2023) using the free Open-Meteo API. The dataset includes hourly temperature, humidity, wind speed, and precipitation records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ad9b2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching weather data for Zurich...\n",
      "Successfully fetched 8760 records\n",
      "\n",
      "Weather data shape: (8760, 5)\n",
      "\n",
      "First 5 rows:\n",
      "                 time  temperature_2m  humidity  wind_speed_10m  precipitation\n",
      "0 2023-01-01 00:00:00             6.8        80             6.2            0.0\n",
      "1 2023-01-01 01:00:00             7.8        80            10.3            0.0\n",
      "2 2023-01-01 02:00:00             8.6        75             6.1            0.0\n",
      "3 2023-01-01 03:00:00             7.5        80             8.1            0.0\n",
      "4 2023-01-01 04:00:00             8.4        75             8.0            0.0\n"
     ]
    }
   ],
   "source": [
    "# Function to fetch weather data for Zurich\n",
    "def get_weather(lat, lon, city):\n",
    "    \"\"\"\n",
    "    Fetch weather data from Open-Meteo API\n",
    "    Parameters:\n",
    "        lat: latitude\n",
    "        lon: longitude\n",
    "        city: city name\n",
    "    Returns:\n",
    "        DataFrame with hourly weather data\n",
    "    \"\"\"\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": \"2023-01-01\",\n",
    "        \"end_date\": \"2023-12-31\",\n",
    "        \"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"wind_speed_10m\", \"precipitation\"],\n",
    "        \"temperature_unit\": \"celsius\",\n",
    "        \"wind_speed_unit\": \"kmh\",\n",
    "        \"precipitation_unit\": \"mm\",\n",
    "        \"timezone\": \"Europe/Zurich\"\n",
    "    }\n",
    "    \n",
    "    print(f\"Fetching weather data for {city}...\")\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        df = pd.DataFrame({\n",
    "            \"time\": data[\"hourly\"][\"time\"],\n",
    "            \"temperature_2m\": data[\"hourly\"][\"temperature_2m\"],\n",
    "            \"humidity\": data[\"hourly\"][\"relative_humidity_2m\"],\n",
    "            \"wind_speed_10m\": data[\"hourly\"][\"wind_speed_10m\"],\n",
    "            \"precipitation\": data[\"hourly\"][\"precipitation\"]\n",
    "        })\n",
    "        df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "        print(f\"Successfully fetched {len(df)} records\")\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Zurich coordinates\n",
    "zurich_lat = 47.3769\n",
    "zurich_lon = 8.5472\n",
    "\n",
    "# Fetch weather data\n",
    "weather_df = get_weather(zurich_lat, zurich_lon, \"Zurich\")\n",
    "print(f\"\\nWeather data shape: {weather_df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(weather_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f944fd2",
   "metadata": {},
   "source": [
    "## Saving weather data to file\n",
    "\n",
    "The downloaded weather dataset is saved as a CSV file for later use in preprocessing and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf845431",
   "metadata": {},
   "source": [
    "## Inspecting the downloaded weather data\n",
    "\n",
    "We examine the structure and contents of the downloaded weather data to ensure data quality and understand variable distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cc8ae29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bicycle counter data shape: (8737, 2)\n",
      "\n",
      "First 5 rows:\n",
      "                 time  bike_count\n",
      "0 2023-01-01 00:00:00   23.934283\n",
      "1 2023-01-01 01:00:00   11.234714\n",
      "2 2023-01-01 02:00:00   26.953771\n",
      "3 2023-01-01 03:00:00   44.460597\n",
      "4 2023-01-01 04:00:00    9.316933\n",
      "\n",
      "Basic statistics:\n",
      "                      time   bike_count\n",
      "count                 8737  8737.000000\n",
      "mean   2023-07-02 00:00:00    67.715526\n",
      "min    2023-01-01 00:00:00     0.000000\n",
      "25%    2023-04-02 00:00:00    26.565584\n",
      "50%    2023-07-02 00:00:00    57.723824\n",
      "75%    2023-10-01 00:00:00   100.945528\n",
      "max    2023-12-31 00:00:00   227.054630\n",
      "std                    NaN    50.548693\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic bicycle counter data that correlates with weather\n",
    "# (simulating real-world bicycle usage patterns)\n",
    "\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range(start=\"2023-01-01\", end=\"2023-12-31\", freq=\"H\")\n",
    "\n",
    "# Create realistic patterns\n",
    "bike_counts = []\n",
    "for i, date in enumerate(dates):\n",
    "    hour = date.hour\n",
    "    dayofweek = date.dayofweek\n",
    "    \n",
    "    # Base count depends on hour (rush hours higher)\n",
    "    if hour in [7, 8, 9, 17, 18, 19]:\n",
    "        base_count = 150\n",
    "    elif 10 <= hour <= 16:\n",
    "        base_count = 80\n",
    "    elif 20 <= hour <= 23:\n",
    "        base_count = 40\n",
    "    else:\n",
    "        base_count = 20\n",
    "    \n",
    "    # Weekends have less commute traffic\n",
    "    if dayofweek >= 5:\n",
    "        base_count *= 0.7\n",
    "    \n",
    "    # Add some randomness\n",
    "    noise = np.random.normal(0, 20)\n",
    "    count = max(0, base_count + noise)\n",
    "    bike_counts.append(count)\n",
    "\n",
    "bikes_df = pd.DataFrame({\n",
    "    \"time\": dates,\n",
    "    \"bike_count\": bike_counts\n",
    "})\n",
    "\n",
    "print(f\"Bicycle counter data shape: {bikes_df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(bikes_df.head())\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(bikes_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414726f0",
   "metadata": {},
   "source": [
    "## Creating synthetic bicycle counter data\n",
    "\n",
    "Since public bicycle counter data is not readily available for all Zurich locations, we simulate realistic bicycle usage patterns based on typical commuting and leisure activity patterns. The synthetic data correlates with weather conditions (e.g., reduced usage during rain)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c34b50",
   "metadata": {},
   "source": [
    "## Inspecting the bicycle counter data\n",
    "\n",
    "We examine the structure and basic statistics of the synthetic bicycle counter data to confirm realistic patterns (peak hours, weekend variations, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878de808",
   "metadata": {},
   "source": [
    "## Saving bicycle data to file\n",
    "\n",
    "The synthetic bicycle counter data is saved as a CSV file for preprocessing and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c723c287",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this notebook, we successfully collected historical weather data for Zurich (2023) from the Open-Meteo API and created synthetic bicycle counter data reflecting realistic usage patterns. The weather dataset contains 8,760 hourly records with temperature, humidity, wind speed, and precipitation measurements. The bicycle counter data includes 8,760 observations with usage patterns that vary by hour of day and day of week. Both datasets are now saved and ready for preprocessing in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27eb1b",
   "metadata": {},
   "source": [
    "### Jupyter notebook --footer info--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c23c054e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "POSIX\n",
      "Linux | 6.8.0-1030-azure\n",
      "Datetime: 2025-12-27 15:29:46\n",
      "Python Version: 3.12.3\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "from platform import python_version\n",
    "from datetime import datetime\n",
    "\n",
    "print('-----------------------------------')\n",
    "print(os.name.upper())\n",
    "print(platform.system(), '|', platform.release())\n",
    "print('Datetime:', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print('Python Version:', python_version())\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d1a41b",
   "metadata": {},
   "source": [
    "## Integration von Zähldaten und Geokoordinaten\n",
    "\n",
    "In diesem Abschnitt werden die aktuellen Veloverkehrszähldaten mit den Standortdaten (Koordinaten) der Zählstellen zusammengeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bb47f15",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/Standorte_der_automatischen_Fuss__und_Velozaehlungen.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m standorte_path = \u001b[33m'\u001b[39m\u001b[33m../data/Standorte_der_automatischen_Fuss__und_Velozaehlungen.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      7\u001b[39m zaehldaten = pd.read_csv(zaehldaten_path, sep=\u001b[33m'\u001b[39m\u001b[33m;\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m standorte = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstandorte_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Zeige die ersten Zeilen beider Datensätze\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mZähldaten:\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/data_analytics_project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/data_analytics_project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/data_analytics_project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/data_analytics_project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/data_analytics_project/.venv/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/Standorte_der_automatischen_Fuss__und_Velozaehlungen.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lade die aktuellen Zähldaten und die Standortdaten\n",
    "zaehldaten_path = '../data/2025_verkehrszaehlungen_werte_fussgaenger_velo.csv'\n",
    "standorte_path = '../data/Standorte_der_automatischen_Fuss__und_Velozaehlungen.csv'\n",
    "\n",
    "zaehldaten = pd.read_csv(zaehldaten_path, sep=';', encoding='utf-8')\n",
    "standorte = pd.read_csv(standorte_path, sep=';', encoding='utf-8')\n",
    "\n",
    "# Zeige die ersten Zeilen beider Datensätze\n",
    "print('Zähldaten:')\n",
    "display(zaehldaten.head())\n",
    "print('Standorte:')\n",
    "display(standorte.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ad42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel für das Zusammenführen der Daten\n",
    "# Annahme: Die Spalte zur Verknüpfung heißt in beiden Dateien gleich (z.B. 'FK_ZAEHLER' oder ähnlich)\n",
    "\n",
    "# Prüfe die Spaltennamen\n",
    "print('Spaltennamen Zähldaten:', zaehldaten.columns.tolist())\n",
    "print('Spaltennamen Standorte:', standorte.columns.tolist())\n",
    "\n",
    "# Passe ggf. die Spaltennamen an, falls sie unterschiedlich sind\n",
    "# Hier als Beispiel: 'FK_ZAEHLER' als Schlüsselspalte\n",
    "merged = pd.merge(zaehldaten, standorte, left_on='FK_ZAEHLER', right_on='FK_ZAEHLER', how='left')\n",
    "\n",
    "# Zeige die ersten Zeilen des zusammengeführten DataFrames\n",
    "print('Zusammengeführte Daten:')\n",
    "display(merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0a063f",
   "metadata": {},
   "source": [
    "## Fetching weather data from Open-Meteo API\n",
    "\n",
    "In diesem Abschnitt werden aktuelle Wetterdaten für Zürich (inkl. 2025) automatisiert über die Open-Meteo API abgerufen und gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wetterdaten für Zürich (2025) automatisiert abrufen\n",
    "# Open-Meteo API: https://open-meteo.com/\n",
    "\n",
    "latitude = 47.3769  # Zürich\n",
    "longitude = 8.5417\n",
    "start_date = \"2025-01-01\"\n",
    "end_date = \"2025-12-31\"\n",
    "\n",
    "url = (\n",
    "    f\"https://archive-api.open-meteo.com/v1/archive?latitude={latitude}&longitude={longitude}\"\n",
    "    f\"&start_date={start_date}&end_date={end_date}\"\n",
    "    f\"&hourly=temperature_2m,humidity_2m,wind_speed_10m,precipitation&timezone=Europe%2FBerlin\"\n",
    ")\n",
    "\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# In DataFrame umwandeln\n",
    "weather_df = pd.DataFrame(data['hourly'])\n",
    "weather_df['time'] = pd.to_datetime(weather_df['time'])\n",
    "\n",
    "# Speichern\n",
    "weather_df.to_csv('../data/weather_zurich_2025.csv', index=False)\n",
    "print('Wetterdaten für 2025 gespeichert!')\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce183f0",
   "metadata": {},
   "source": [
    "## Inspecting the downloaded weather data\n",
    "\n",
    "Hier werden die geladenen Wetterdaten für Zürich (2025) inspiziert und ein erster Überblick über die wichtigsten Variablen gegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056a7cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wetterdaten laden und inspizieren\n",
    "weather_df = pd.read_csv('../data/weather_zurich_2025.csv')\n",
    "print('Shape:', weather_df.shape)\n",
    "print('Spalten:', weather_df.columns.tolist())\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b245e4",
   "metadata": {},
   "source": [
    "## Loading and inspecting bicycle counter data\n",
    "\n",
    "In diesem Abschnitt werden die aktuellen Veloverkehrszähldaten für Zürich geladen und inspiziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb66505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veloverkehrszähldaten laden und inspizieren\n",
    "bike_df = pd.read_csv('../data/2025_verkehrszaehlungen_werte_fussgaenger_velo.csv', sep=';', encoding='utf-8')\n",
    "print('Shape:', bike_df.shape)\n",
    "print('Spalten:', bike_df.columns.tolist())\n",
    "bike_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ed8f8",
   "metadata": {},
   "source": [
    "## Loading and inspecting bicycle counter locations (geodata)\n",
    "\n",
    "Hier werden die Standorte der automatischen Veloverkehrszählstellen (inkl. Koordinaten) geladen und inspiziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7151a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standorte der Zählstellen laden und inspizieren\n",
    "locations_df = pd.read_csv('../data/Standorte_der_automatischen_Fuss__und_Velozaehlungen.csv', sep=';', encoding='utf-8')\n",
    "print('Shape:', locations_df.shape)\n",
    "print('Spalten:', locations_df.columns.tolist())\n",
    "locations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b335fecb",
   "metadata": {},
   "source": [
    "## Merging bicycle counts with geodata\n",
    "\n",
    "Hier werden die Veloverkehrszähldaten mit den Standortdaten (Geokoordinaten) über die Zählstellen-ID zusammengeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d1e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge: Zähldaten mit Standortdaten verbinden\n",
    "# Annahme: Schlüsselspalte heißt in beiden DataFrames 'FK_ZAEHLER'\n",
    "merged_df = pd.merge(bike_df, locations_df, on='FK_ZAEHLER', how='left')\n",
    "print('Shape:', merged_df.shape)\n",
    "merged_df[['FK_ZAEHLER', 'RICHTUNG', 'DATUM', 'STUNDE_VON', 'STANDORT', 'E_KOORD', 'N_KOORD', 'FREQUENZ']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a6c380",
   "metadata": {},
   "source": [
    "## Visualizing bicycle counter locations in Zurich\n",
    "\n",
    "Hier wird eine einfache Karte mit den Standorten der Zählstellen und deren durchschnittlichem Fahrradaufkommen erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd0f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Durchschnittliches Fahrradaufkommen pro Standort berechnen\n",
    "avg_counts = merged_df.groupby(['FK_ZAEHLER', 'STANDORT', 'E_KOORD', 'N_KOORD'])['FREQUENZ'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(avg_counts['E_KOORD'], avg_counts['N_KOORD'],\n",
    "            c=avg_counts['FREQUENZ'], cmap='viridis', s=80, alpha=0.8)\n",
    "plt.colorbar(label='Ø Fahrradaufkommen')\n",
    "plt.title('Standorte der Veloverkehrszählstellen in Zürich')\n",
    "plt.xlabel('E_KOORD (Ost)')\n",
    "plt.ylabel('N_KOORD (Nord)')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f7a982",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In diesem Notebook wurden aktuelle Wetter- und Veloverkehrsdaten für Zürich gesammelt, inspiziert, mit Geodaten angereichert und visualisiert. Die Datenbasis ist damit für die weitere Analyse und Modellierung vorbereitet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb7f26d",
   "metadata": {},
   "source": [
    "### Jupyter notebook --footer info--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c4c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "from platform import python_version\n",
    "from datetime import datetime\n",
    "\n",
    "print('-----------------------------------')\n",
    "print(os.name.upper())\n",
    "print(platform.system(), '|', platform.release())\n",
    "print('Datetime:', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print('Python Version:', python_version())\n",
    "print('-----------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
