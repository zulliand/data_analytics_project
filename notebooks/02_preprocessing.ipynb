{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41020117",
   "metadata": {},
   "source": [
    "## Libraries and settings\n",
    "\n",
    "Import the required libraries and set the main settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cc3fb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/data_analytics_project/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0887c0d8",
   "metadata": {},
   "source": [
    "# Weather & Bicycle Usage â€“ Data Preprocessing\n",
    "\n",
    "This notebook cleans, merges, and prepares the collected weather and bicycle traffic data for Zurich for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d9a1ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather data shape: (8760, 5)\n",
      "                 time  temperature_2m  relative_humidity_2m  wind_speed_10m  \\\n",
      "0 2025-01-01 00:00:00            -1.5                    98             1.0   \n",
      "1 2025-01-01 01:00:00            -1.9                    99             2.6   \n",
      "2 2025-01-01 02:00:00            -3.2                   100             2.4   \n",
      "3 2025-01-01 03:00:00            -3.0                   100             4.7   \n",
      "4 2025-01-01 04:00:00            -2.8                   100             5.0   \n",
      "\n",
      "   precipitation  \n",
      "0            0.0  \n",
      "1            0.0  \n",
      "2            0.0  \n",
      "3            0.0  \n",
      "4            0.0  \n",
      "\n",
      "Available columns: ['time', 'temperature_2m', 'relative_humidity_2m', 'wind_speed_10m', 'precipitation']\n",
      "\n",
      "Data types:\n",
      "time                    datetime64[ns]\n",
      "temperature_2m                 float64\n",
      "relative_humidity_2m             int64\n",
      "wind_speed_10m                 float64\n",
      "precipitation                  float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load hourly weather data with all features\n",
    "weather_df = pd.read_csv(\"../data/weather_zurich_2025.csv\")\n",
    "weather_df['time'] = pd.to_datetime(weather_df['time'])\n",
    "\n",
    "print(\"Weather data shape:\", weather_df.shape)\n",
    "print(weather_df.head())\n",
    "print(\"\\nAvailable columns:\", weather_df.columns.tolist())\n",
    "print(\"\\nData types:\")\n",
    "print(weather_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae54098",
   "metadata": {},
   "source": [
    "## Loading datasets\n",
    "\n",
    "We load both the weather and bicycle counter data from the CSV files generated in the data collection phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d56af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bicycle data shape: (838029, 8)\n",
      "   FK_STANDORT             DATUM  VELO_IN  VELO_OUT  FUSS_IN  FUSS_OUT  \\\n",
      "0         4241  2025-01-01T00:00      3.0       0.0      NaN       NaN   \n",
      "1         2989  2025-01-01T00:00      1.0       2.0      NaN       NaN   \n",
      "2         2991  2025-01-01T00:00     18.0       2.0      NaN       NaN   \n",
      "3         4255  2025-01-01T00:00      0.0       0.0      NaN       NaN   \n",
      "4         4242  2025-01-01T00:00      1.0       0.0      NaN       NaN   \n",
      "\n",
      "       OST     NORD  \n",
      "0  2682297  1248328  \n",
      "1  2682278  1248324  \n",
      "2  2682756  1247323  \n",
      "3  2682881  1246549  \n",
      "4  2682337  1248451  \n",
      "\n",
      "Data types:\n",
      "FK_STANDORT      int64\n",
      "DATUM           object\n",
      "VELO_IN        float64\n",
      "VELO_OUT       float64\n",
      "FUSS_IN        float64\n",
      "FUSS_OUT       float64\n",
      "OST              int64\n",
      "NORD             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load bicycle counter data\n",
    "bikes_df = pd.read_csv(\"../data/2025_verkehrszaehlungen_werte_fussgaenger_velo.csv\")\n",
    "print(\"Bicycle data shape:\", bikes_df.shape)\n",
    "print(bikes_df.head())\n",
    "print(\"\\nData types:\")\n",
    "print(bikes_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbdaeff",
   "metadata": {},
   "source": [
    "## Cleaning and handling missing values\n",
    "\n",
    "We convert time columns to datetime format and remove any rows with missing values to ensure data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a39988ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After datetime conversion:\n",
      "Bikes DATUM data type: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Convert date column in bikes_df to datetime\n",
    "bikes_df[\"DATUM\"] = pd.to_datetime(bikes_df[\"DATUM\"])\n",
    "print(\"After datetime conversion:\")\n",
    "print(\"Bikes DATUM data type:\", bikes_df[\"DATUM\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "261fb0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated daily weather data:\n",
      "        date  temp_mean  humidity_mean  wind_speed_mean  precipitation_sum\n",
      "0 2025-01-01   0.650000      86.083333         4.750000                0.0\n",
      "1 2025-01-02   3.141667      76.958333        12.662500               14.5\n",
      "2 2025-01-03  -0.308333      87.333333         5.908333                1.4\n",
      "3 2025-01-04  -1.900000      80.916667         3.183333                0.6\n",
      "4 2025-01-05   1.845833      93.000000         4.608333               15.0\n",
      "\n",
      "Shape: (365, 5)\n",
      "\n",
      "Aggregated daily bicycle data:\n",
      "        date  VELO_IN  VELO_OUT  FUSS_IN  FUSS_OUT\n",
      "0 2025-01-01   5094.0    2558.0   1188.0    1099.0\n",
      "1 2025-01-02   5086.0    2423.0    541.0     448.0\n",
      "2 2025-01-03   9073.0    4420.0    450.0     404.0\n",
      "3 2025-01-04   7129.0    3551.0    457.0     388.0\n",
      "4 2025-01-05   5000.0    2641.0    630.0     565.0\n",
      "Shape: (359, 5)\n"
     ]
    }
   ],
   "source": [
    "# --- Aggregate weather data to daily level ---\n",
    "# Extract date from time\n",
    "weather_df['date'] = weather_df['time'].dt.date\n",
    "\n",
    "# Aggregate weather features to daily level\n",
    "daily_weather = weather_df.groupby('date').agg({\n",
    "    'temperature_2m': 'mean',\n",
    "    'relative_humidity_2m': 'mean',\n",
    "    'wind_speed_10m': 'mean',\n",
    "    'precipitation': 'sum'  # Sum for precipitation (total per day)\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "daily_weather.rename(columns={\n",
    "    'temperature_2m': 'temp_mean',\n",
    "    'relative_humidity_2m': 'humidity_mean',\n",
    "    'wind_speed_10m': 'wind_speed_mean',\n",
    "    'precipitation': 'precipitation_sum'\n",
    "}, inplace=True)\n",
    "\n",
    "# Convert 'date' back to datetime for merging\n",
    "daily_weather['date'] = pd.to_datetime(daily_weather['date'])\n",
    "\n",
    "print('Aggregated daily weather data:')\n",
    "print(daily_weather.head())\n",
    "print(f'\\nShape: {daily_weather.shape}')\n",
    "\n",
    "# --- Aggregate bicycle data to daily level ---\n",
    "# Create a new column with only the date (no time)\n",
    "bikes_df['DATE_ONLY'] = bikes_df['DATUM'].dt.date\n",
    "\n",
    "# Sum all bike counts per day (across all locations)\n",
    "daily_bikes = bikes_df.groupby('DATE_ONLY').agg({\n",
    "    'VELO_IN': 'sum',\n",
    "    'VELO_OUT': 'sum',\n",
    "    'FUSS_IN': 'sum',\n",
    "    'FUSS_OUT': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "daily_bikes.rename(columns={'DATE_ONLY': 'date'}, inplace=True)\n",
    "# Convert 'date' back to datetime for merging\n",
    "daily_bikes['date'] = pd.to_datetime(daily_bikes['date'])\n",
    "\n",
    "print('\\nAggregated daily bicycle data:')\n",
    "print(daily_bikes.head())\n",
    "print(f'Shape: {daily_bikes.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8daae27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in daily weather data:\n",
      "date                 0\n",
      "temp_mean            0\n",
      "humidity_mean        0\n",
      "wind_speed_mean      0\n",
      "precipitation_sum    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in daily bicycle data:\n",
      "date        0\n",
      "VELO_IN     0\n",
      "VELO_OUT    0\n",
      "FUSS_IN     0\n",
      "FUSS_OUT    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in aggregated data\n",
    "print(\"Missing values in daily weather data:\")\n",
    "print(daily_weather.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in daily bicycle data:\")\n",
    "print(daily_bikes.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fd58c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping missing values:\n",
      "Daily weather data shape: (365, 5)\n",
      "Daily bicycle data shape: (359, 5)\n"
     ]
    }
   ],
   "source": [
    "# Drop missing values\n",
    "daily_weather = daily_weather.dropna()\n",
    "daily_bikes = daily_bikes.dropna()\n",
    "\n",
    "print(\"After dropping missing values:\")\n",
    "print(\"Daily weather data shape:\", daily_weather.shape)\n",
    "print(\"Daily bicycle data shape:\", daily_bikes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d4b182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in daily weather data: 0\n",
      "Duplicates in daily bicycle data: 0\n",
      "\n",
      "After removing duplicates:\n",
      "Daily weather data shape: (365, 5)\n",
      "Daily bicycle data shape: (359, 5)\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(\"Duplicates in daily weather data:\", daily_weather.duplicated().sum())\n",
    "print(\"Duplicates in daily bicycle data:\", daily_bikes.duplicated().sum())\n",
    "\n",
    "# Drop duplicates if any\n",
    "daily_weather = daily_weather.drop_duplicates()\n",
    "daily_bikes = daily_bikes.drop_duplicates()\n",
    "\n",
    "print(\"\\nAfter removing duplicates:\")\n",
    "print(\"Daily weather data shape:\", daily_weather.shape)\n",
    "print(\"Daily bicycle data shape:\", daily_bikes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb67444",
   "metadata": {},
   "source": [
    "## Merging weather and bicycle datasets\n",
    "\n",
    "We perform an inner join on the time column to combine both datasets into a single analysis-ready dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c984edf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data shape: (359, 9)\n",
      "\n",
      "Columns: ['date', 'temp_mean', 'humidity_mean', 'wind_speed_mean', 'precipitation_sum', 'VELO_IN', 'VELO_OUT', 'FUSS_IN', 'FUSS_OUT']\n",
      "\n",
      "First 5 rows:\n",
      "        date  temp_mean  humidity_mean  wind_speed_mean  precipitation_sum  \\\n",
      "0 2025-01-01   0.650000      86.083333         4.750000                0.0   \n",
      "1 2025-01-02   3.141667      76.958333        12.662500               14.5   \n",
      "2 2025-01-03  -0.308333      87.333333         5.908333                1.4   \n",
      "3 2025-01-04  -1.900000      80.916667         3.183333                0.6   \n",
      "4 2025-01-05   1.845833      93.000000         4.608333               15.0   \n",
      "\n",
      "   VELO_IN  VELO_OUT  FUSS_IN  FUSS_OUT  \n",
      "0   5094.0    2558.0   1188.0    1099.0  \n",
      "1   5086.0    2423.0    541.0     448.0  \n",
      "2   9073.0    4420.0    450.0     404.0  \n",
      "3   7129.0    3551.0    457.0     388.0  \n",
      "4   5000.0    2641.0    630.0     565.0  \n",
      "\n",
      "Data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 359 entries, 0 to 358\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   date               359 non-null    datetime64[ns]\n",
      " 1   temp_mean          359 non-null    float64       \n",
      " 2   humidity_mean      359 non-null    float64       \n",
      " 3   wind_speed_mean    359 non-null    float64       \n",
      " 4   precipitation_sum  359 non-null    float64       \n",
      " 5   VELO_IN            359 non-null    float64       \n",
      " 6   VELO_OUT           359 non-null    float64       \n",
      " 7   FUSS_IN            359 non-null    float64       \n",
      " 8   FUSS_OUT           359 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(8)\n",
      "memory usage: 25.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Merge weather and aggregated bicycle data on date\n",
    "merged_df = pd.merge(daily_weather, daily_bikes, on=\"date\", how=\"inner\")\n",
    "\n",
    "print(\"Merged data shape:\", merged_df.shape)\n",
    "print(\"\\nColumns:\", merged_df.columns.tolist())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(merged_df.head())\n",
    "print(\"\\nData info:\")\n",
    "print(merged_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ba0f463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistics:\n",
      "                      date   temp_mean  humidity_mean  wind_speed_mean  \\\n",
      "count                  359  359.000000     359.000000       359.000000   \n",
      "mean   2025-06-29 00:00:00   10.576346      81.147516         5.490796   \n",
      "min    2025-01-01 00:00:00   -2.887500      50.583333         1.025000   \n",
      "25%    2025-03-31 12:00:00    4.533333      74.895833         2.987500   \n",
      "50%    2025-06-29 00:00:00    9.954167      82.333333         4.662500   \n",
      "75%    2025-09-26 12:00:00   16.435417      88.416667         6.945833   \n",
      "max    2025-12-25 00:00:00   26.787500      98.708333        21.987500   \n",
      "std                    NaN    7.308711      10.197086         3.368768   \n",
      "\n",
      "       precipitation_sum       VELO_IN      VELO_OUT      FUSS_IN     FUSS_OUT  \n",
      "count         359.000000    359.000000    359.000000   359.000000   359.000000  \n",
      "mean            3.530641  23350.487465  11717.409471  1220.885794   941.256267  \n",
      "min             0.000000   1373.000000   1241.000000     0.000000     0.000000  \n",
      "25%             0.000000  17209.500000   8603.000000   622.500000   492.000000  \n",
      "50%             0.300000  22996.000000  11533.000000  1000.000000   837.000000  \n",
      "75%             4.250000  28954.000000  14785.000000  1643.000000  1286.500000  \n",
      "max            42.300000  47470.000000  23479.000000  4116.000000  3340.000000  \n",
      "std             6.388910   9144.180319   4650.774839   795.581763   558.080430  \n"
     ]
    }
   ],
   "source": [
    "# Basic statistics\n",
    "print(\"Basic statistics:\")\n",
    "print(merged_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18c635dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to ../data/merged_weather_bikes.csv\n"
     ]
    }
   ],
   "source": [
    "# Save merged data\n",
    "merged_df.to_csv(\"../data/merged_weather_bikes.csv\", index=False)\n",
    "print(\"Merged data saved to ../data/merged_weather_bikes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca8c5eb",
   "metadata": {},
   "source": [
    "## Saving cleaned dataset\n",
    "\n",
    "The merged and cleaned dataset is saved as a CSV file for use in exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c759936",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this notebook, we successfully cleaned and merged the weather and bicycle counter datasets for Zurich. We aggregated hourly weather data (temperature, humidity, wind speed, precipitation) to daily means/sums and combined them with daily bicycle counts. Missing values were removed and duplicates were eliminated. The final merged dataset contains daily observations with comprehensive weather features (temp_mean, humidity_mean, wind_speed_mean, precipitation_sum) and bicycle counts. The cleaned dataset is now ready for exploratory data analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73167592",
   "metadata": {},
   "source": [
    "### Jupyter notebook --footer info--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5d877ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "POSIX\n",
      "Linux | 6.8.0-1030-azure\n",
      "Datetime: 2026-01-02 13:50:38\n",
      "Python Version: 3.12.1\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "from platform import python_version\n",
    "from datetime import datetime\n",
    "\n",
    "print('-----------------------------------')\n",
    "print(os.name.upper())\n",
    "print(platform.system(), '|', platform.release())\n",
    "print('Datetime:', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print('Python Version:', python_version())\n",
    "print('-----------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
